{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wrist_angle_predictor2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ninaf-bot/neuralnetwork/blob/master/wrist_angle_predictor2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoKG5m2UX2EG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import math\n",
        "\n",
        "n=0\n",
        "\n",
        "emg = pd.read_csv('/content/25april 38400 delay afternoon features 2-edited.csv')\n",
        "emg['O']=emg['O'].replace(30,1)\n",
        "emg['O']=emg['O'].replace(60,2)\n",
        "emg['O']=emg['O'].replace(90,3)\n",
        "emg['O']=emg['O'].replace(120,4)\n",
        "emg['O']=emg['O'].replace(150,5)\n",
        "emgin=emg.drop(['O'],1)\n",
        "#emgin=emgin[['A','H','I','J']]\n",
        "emgin=np.array(emgin)\n",
        "emg_labels=emg['O']\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbiTlPKmkLWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=pd.DataFrame()\n",
        "b=pd.DataFrame()\n",
        "a=emg['A']\n",
        "b=emg['O']\n",
        "for i in ['B','C','D','E','F','G','H','I','J']:\n",
        "   a=a.append(emg[i]).reset_index(drop=True)\n",
        "   b=b.append(emg['O']).reset_index(drop=True)\n",
        "c=pd.DataFrame({'reading':a ,'output':b})\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNEpJiMPEMNx",
        "colab_type": "code",
        "outputId": "f44a7201-3e28-4ae9-a271-e2734605a2bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "d=[]\n",
        "e=[]\n",
        "f=[]\n",
        "g=[]\n",
        "depth=6\n",
        "sum_r=c.loc[0,'reading']\n",
        "mean=c.loc[0,'reading']\n",
        "rms=c.loc[0,'reading']\n",
        "square_sum=c.loc[0,'reading']*c.loc[0,'reading']\n",
        "d.append(mean)\n",
        "e.append(rms)\n",
        "f.append(sum_r)\n",
        "g.append(square_sum)\n",
        "pervious_output=c.loc[0,'output']\n",
        "count=1\n",
        "for i in range(1,len(c)):\n",
        "  if c.loc[i,'output']==pervious_output:\n",
        "    sum_r=sum_r+c.loc[i,'reading']\n",
        "    square_sum=square_sum+c.loc[i,'reading']*c.loc[i,'reading']\n",
        "    count+1\n",
        "    mean=sum_r/count\n",
        "    rms=math.sqrt(square_sum/count)\n",
        "    d.append(mean)\n",
        "    e.append(rms)\n",
        "    f.append(sum_r)\n",
        "    g.append(square_sum)\n",
        "    pervious_output=c.loc[i,'output']\n",
        "  elif c.loc[i,'output']!=pervious_output:\n",
        "    sum_r=c.loc[i,'reading']\n",
        "    mean=c.loc[i,'reading']\n",
        "    rms=c.loc[i,'reading']\n",
        "    square_sum=c.loc[i,'reading']*c.loc[i,'reading']\n",
        "    count=1\n",
        "    d.append(mean)\n",
        "    e.append(rms)\n",
        "    f.append(sum_r)\n",
        "    g.append(square_sum)\n",
        "    pervious_output=c.loc[i,'output']\n",
        "\n",
        "c['mean']=d\n",
        "c['rms']=e\n",
        "c['sum']=f\n",
        "c['square_sum']=f\n",
        "c['stddev']=c['mean']-c['reading']\n",
        "\n",
        "\n",
        "deapth=6\n",
        "emg_labels=tf.one_hot(c['output'], depth)\n",
        "sess=tf.Session()\n",
        "with sess as se:\n",
        "  emg_labels=se.run(emg_labels)\n",
        "\n",
        "input1=c.drop(['output'],1)\n",
        "xmax=input1['reading'].max()\n",
        "xmin=input1['reading'].min()\n",
        "ymax=input1['mean'].max()\n",
        "ymin=input1['mean'].min()\n",
        "zmax=input1['stddev'].max()\n",
        "zmin=input1['stddev'].min()\n",
        "wmax=input1['rms'].max()\n",
        "wmin=input1['rms'].min()\n",
        "vmax=input1['sum'].max()\n",
        "vmin=input1['sum'].min()\n",
        "umax=input1['square_sum'].max()\n",
        "umin=input1['square_sum'].min()\n",
        "#xmid=(xmax+xmin)/2\n",
        "#ymid=(ymax+ymin)/2\n",
        "input1['reading']=input1['reading']/xmax\n",
        "input1['mean']=input1['mean']/ymax\n",
        "input1['stddev']=input1['stddev']/zmax\n",
        "input1['rms']=input1['rms']/wmax\n",
        "input1['sum']=input1['sum']/vmax\n",
        "input1['square_sum']=input1['square_sum']/umax\n",
        "#input1['reading']=(input1['reading']-xmid)/x\n",
        "#input1['mean']=(input1['mean']-ymid)/y\n",
        "input1\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reading</th>\n",
              "      <th>mean</th>\n",
              "      <th>rms</th>\n",
              "      <th>sum</th>\n",
              "      <th>stddev</th>\n",
              "      <th>square_sum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.088505</td>\n",
              "      <td>0.000150</td>\n",
              "      <td>0.004467</td>\n",
              "      <td>0.000150</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.088505</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.006317</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.000150</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.088505</td>\n",
              "      <td>0.000449</td>\n",
              "      <td>0.007737</td>\n",
              "      <td>0.000449</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.000449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.088505</td>\n",
              "      <td>0.000599</td>\n",
              "      <td>0.008934</td>\n",
              "      <td>0.000599</td>\n",
              "      <td>0.000450</td>\n",
              "      <td>0.000599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.088505</td>\n",
              "      <td>0.000749</td>\n",
              "      <td>0.009988</td>\n",
              "      <td>0.000749</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.000749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.088505</td>\n",
              "      <td>0.000899</td>\n",
              "      <td>0.010941</td>\n",
              "      <td>0.000899</td>\n",
              "      <td>0.000750</td>\n",
              "      <td>0.000899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.088505</td>\n",
              "      <td>0.001048</td>\n",
              "      <td>0.011818</td>\n",
              "      <td>0.001048</td>\n",
              "      <td>0.000899</td>\n",
              "      <td>0.001048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.089522</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>0.012652</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>0.001049</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.090539</td>\n",
              "      <td>0.001353</td>\n",
              "      <td>0.013452</td>\n",
              "      <td>0.001353</td>\n",
              "      <td>0.001201</td>\n",
              "      <td>0.001353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.091556</td>\n",
              "      <td>0.001508</td>\n",
              "      <td>0.014224</td>\n",
              "      <td>0.001508</td>\n",
              "      <td>0.001354</td>\n",
              "      <td>0.001508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.091556</td>\n",
              "      <td>0.001663</td>\n",
              "      <td>0.014955</td>\n",
              "      <td>0.001663</td>\n",
              "      <td>0.001509</td>\n",
              "      <td>0.001663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.091556</td>\n",
              "      <td>0.001818</td>\n",
              "      <td>0.015653</td>\n",
              "      <td>0.001818</td>\n",
              "      <td>0.001664</td>\n",
              "      <td>0.001818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.091556</td>\n",
              "      <td>0.001973</td>\n",
              "      <td>0.016321</td>\n",
              "      <td>0.001973</td>\n",
              "      <td>0.001820</td>\n",
              "      <td>0.001973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.091556</td>\n",
              "      <td>0.002128</td>\n",
              "      <td>0.016962</td>\n",
              "      <td>0.002128</td>\n",
              "      <td>0.001975</td>\n",
              "      <td>0.002128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.091556</td>\n",
              "      <td>0.002283</td>\n",
              "      <td>0.017580</td>\n",
              "      <td>0.002283</td>\n",
              "      <td>0.002130</td>\n",
              "      <td>0.002283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.091556</td>\n",
              "      <td>0.002438</td>\n",
              "      <td>0.018178</td>\n",
              "      <td>0.002438</td>\n",
              "      <td>0.002285</td>\n",
              "      <td>0.002438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.091556</td>\n",
              "      <td>0.002593</td>\n",
              "      <td>0.018756</td>\n",
              "      <td>0.002593</td>\n",
              "      <td>0.002440</td>\n",
              "      <td>0.002593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.091556</td>\n",
              "      <td>0.002748</td>\n",
              "      <td>0.019316</td>\n",
              "      <td>0.002748</td>\n",
              "      <td>0.002595</td>\n",
              "      <td>0.002748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.090539</td>\n",
              "      <td>0.002901</td>\n",
              "      <td>0.019850</td>\n",
              "      <td>0.002901</td>\n",
              "      <td>0.002750</td>\n",
              "      <td>0.002901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.091556</td>\n",
              "      <td>0.003056</td>\n",
              "      <td>0.020380</td>\n",
              "      <td>0.003056</td>\n",
              "      <td>0.002903</td>\n",
              "      <td>0.003056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.091556</td>\n",
              "      <td>0.003211</td>\n",
              "      <td>0.020898</td>\n",
              "      <td>0.003211</td>\n",
              "      <td>0.003058</td>\n",
              "      <td>0.003211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.092574</td>\n",
              "      <td>0.003367</td>\n",
              "      <td>0.021414</td>\n",
              "      <td>0.003367</td>\n",
              "      <td>0.003214</td>\n",
              "      <td>0.003367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.091556</td>\n",
              "      <td>0.003522</td>\n",
              "      <td>0.021906</td>\n",
              "      <td>0.003522</td>\n",
              "      <td>0.003370</td>\n",
              "      <td>0.003522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.092574</td>\n",
              "      <td>0.003679</td>\n",
              "      <td>0.022399</td>\n",
              "      <td>0.003679</td>\n",
              "      <td>0.003525</td>\n",
              "      <td>0.003679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.092574</td>\n",
              "      <td>0.003836</td>\n",
              "      <td>0.022881</td>\n",
              "      <td>0.003836</td>\n",
              "      <td>0.003682</td>\n",
              "      <td>0.003836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.093591</td>\n",
              "      <td>0.003994</td>\n",
              "      <td>0.023364</td>\n",
              "      <td>0.003994</td>\n",
              "      <td>0.003839</td>\n",
              "      <td>0.003994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.093591</td>\n",
              "      <td>0.004152</td>\n",
              "      <td>0.023836</td>\n",
              "      <td>0.004152</td>\n",
              "      <td>0.003998</td>\n",
              "      <td>0.004152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.094608</td>\n",
              "      <td>0.004313</td>\n",
              "      <td>0.024310</td>\n",
              "      <td>0.004313</td>\n",
              "      <td>0.004156</td>\n",
              "      <td>0.004313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.093591</td>\n",
              "      <td>0.004471</td>\n",
              "      <td>0.024765</td>\n",
              "      <td>0.004471</td>\n",
              "      <td>0.004316</td>\n",
              "      <td>0.004471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.094608</td>\n",
              "      <td>0.004631</td>\n",
              "      <td>0.025221</td>\n",
              "      <td>0.004631</td>\n",
              "      <td>0.004475</td>\n",
              "      <td>0.004631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55050</th>\n",
              "      <td>0.501786</td>\n",
              "      <td>0.867246</td>\n",
              "      <td>0.876401</td>\n",
              "      <td>0.867246</td>\n",
              "      <td>0.867162</td>\n",
              "      <td>0.867246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55051</th>\n",
              "      <td>0.499672</td>\n",
              "      <td>0.868092</td>\n",
              "      <td>0.876764</td>\n",
              "      <td>0.868092</td>\n",
              "      <td>0.868011</td>\n",
              "      <td>0.868092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55052</th>\n",
              "      <td>0.492853</td>\n",
              "      <td>0.868926</td>\n",
              "      <td>0.877117</td>\n",
              "      <td>0.868926</td>\n",
              "      <td>0.868858</td>\n",
              "      <td>0.868926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55053</th>\n",
              "      <td>0.492708</td>\n",
              "      <td>0.869760</td>\n",
              "      <td>0.877469</td>\n",
              "      <td>0.869760</td>\n",
              "      <td>0.869693</td>\n",
              "      <td>0.869760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55054</th>\n",
              "      <td>0.503123</td>\n",
              "      <td>0.870611</td>\n",
              "      <td>0.877836</td>\n",
              "      <td>0.870611</td>\n",
              "      <td>0.870527</td>\n",
              "      <td>0.870611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55055</th>\n",
              "      <td>0.506899</td>\n",
              "      <td>0.871469</td>\n",
              "      <td>0.878209</td>\n",
              "      <td>0.871469</td>\n",
              "      <td>0.871379</td>\n",
              "      <td>0.871469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55056</th>\n",
              "      <td>0.501572</td>\n",
              "      <td>0.872318</td>\n",
              "      <td>0.878574</td>\n",
              "      <td>0.872318</td>\n",
              "      <td>0.872238</td>\n",
              "      <td>0.872318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55057</th>\n",
              "      <td>0.502074</td>\n",
              "      <td>0.873168</td>\n",
              "      <td>0.878939</td>\n",
              "      <td>0.873168</td>\n",
              "      <td>0.873087</td>\n",
              "      <td>0.873168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55058</th>\n",
              "      <td>0.502790</td>\n",
              "      <td>0.874018</td>\n",
              "      <td>0.879305</td>\n",
              "      <td>0.874018</td>\n",
              "      <td>0.873938</td>\n",
              "      <td>0.874018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55059</th>\n",
              "      <td>0.512102</td>\n",
              "      <td>0.874885</td>\n",
              "      <td>0.879685</td>\n",
              "      <td>0.874885</td>\n",
              "      <td>0.874790</td>\n",
              "      <td>0.874885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55060</th>\n",
              "      <td>0.513111</td>\n",
              "      <td>0.875753</td>\n",
              "      <td>0.880066</td>\n",
              "      <td>0.875753</td>\n",
              "      <td>0.875657</td>\n",
              "      <td>0.875753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55061</th>\n",
              "      <td>0.509301</td>\n",
              "      <td>0.876615</td>\n",
              "      <td>0.880442</td>\n",
              "      <td>0.876615</td>\n",
              "      <td>0.876526</td>\n",
              "      <td>0.876615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55062</th>\n",
              "      <td>0.505269</td>\n",
              "      <td>0.877470</td>\n",
              "      <td>0.880811</td>\n",
              "      <td>0.877470</td>\n",
              "      <td>0.877389</td>\n",
              "      <td>0.877470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55063</th>\n",
              "      <td>0.503785</td>\n",
              "      <td>0.878323</td>\n",
              "      <td>0.881178</td>\n",
              "      <td>0.878323</td>\n",
              "      <td>0.878244</td>\n",
              "      <td>0.878323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55064</th>\n",
              "      <td>0.500663</td>\n",
              "      <td>0.879170</td>\n",
              "      <td>0.881540</td>\n",
              "      <td>0.879170</td>\n",
              "      <td>0.879098</td>\n",
              "      <td>0.879170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55065</th>\n",
              "      <td>0.503140</td>\n",
              "      <td>0.880022</td>\n",
              "      <td>0.881906</td>\n",
              "      <td>0.880022</td>\n",
              "      <td>0.879946</td>\n",
              "      <td>0.880022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55066</th>\n",
              "      <td>0.500364</td>\n",
              "      <td>0.880868</td>\n",
              "      <td>0.882267</td>\n",
              "      <td>0.880868</td>\n",
              "      <td>0.880798</td>\n",
              "      <td>0.880868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55067</th>\n",
              "      <td>0.500318</td>\n",
              "      <td>0.881715</td>\n",
              "      <td>0.882628</td>\n",
              "      <td>0.881715</td>\n",
              "      <td>0.881645</td>\n",
              "      <td>0.881715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55068</th>\n",
              "      <td>0.499835</td>\n",
              "      <td>0.882561</td>\n",
              "      <td>0.882989</td>\n",
              "      <td>0.882561</td>\n",
              "      <td>0.882493</td>\n",
              "      <td>0.882561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55069</th>\n",
              "      <td>0.507083</td>\n",
              "      <td>0.883419</td>\n",
              "      <td>0.883360</td>\n",
              "      <td>0.883419</td>\n",
              "      <td>0.883340</td>\n",
              "      <td>0.883419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55070</th>\n",
              "      <td>0.504203</td>\n",
              "      <td>0.884272</td>\n",
              "      <td>0.883726</td>\n",
              "      <td>0.884272</td>\n",
              "      <td>0.884198</td>\n",
              "      <td>0.884272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55071</th>\n",
              "      <td>0.510440</td>\n",
              "      <td>0.885136</td>\n",
              "      <td>0.884101</td>\n",
              "      <td>0.885136</td>\n",
              "      <td>0.885052</td>\n",
              "      <td>0.885136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55072</th>\n",
              "      <td>0.515055</td>\n",
              "      <td>0.886008</td>\n",
              "      <td>0.884484</td>\n",
              "      <td>0.886008</td>\n",
              "      <td>0.885917</td>\n",
              "      <td>0.886008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55073</th>\n",
              "      <td>0.506062</td>\n",
              "      <td>0.886864</td>\n",
              "      <td>0.884852</td>\n",
              "      <td>0.886864</td>\n",
              "      <td>0.886789</td>\n",
              "      <td>0.886864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55074</th>\n",
              "      <td>0.505512</td>\n",
              "      <td>0.887720</td>\n",
              "      <td>0.885220</td>\n",
              "      <td>0.887720</td>\n",
              "      <td>0.887647</td>\n",
              "      <td>0.887720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55075</th>\n",
              "      <td>0.506169</td>\n",
              "      <td>0.888576</td>\n",
              "      <td>0.885588</td>\n",
              "      <td>0.888576</td>\n",
              "      <td>0.888503</td>\n",
              "      <td>0.888576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55076</th>\n",
              "      <td>0.505644</td>\n",
              "      <td>0.889432</td>\n",
              "      <td>0.885956</td>\n",
              "      <td>0.889432</td>\n",
              "      <td>0.889360</td>\n",
              "      <td>0.889432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55077</th>\n",
              "      <td>0.507965</td>\n",
              "      <td>0.890292</td>\n",
              "      <td>0.886327</td>\n",
              "      <td>0.890292</td>\n",
              "      <td>0.890217</td>\n",
              "      <td>0.890292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55078</th>\n",
              "      <td>0.512410</td>\n",
              "      <td>0.891159</td>\n",
              "      <td>0.886704</td>\n",
              "      <td>0.891159</td>\n",
              "      <td>0.891077</td>\n",
              "      <td>0.891159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55079</th>\n",
              "      <td>0.517087</td>\n",
              "      <td>0.892034</td>\n",
              "      <td>0.887088</td>\n",
              "      <td>0.892034</td>\n",
              "      <td>0.891945</td>\n",
              "      <td>0.892034</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>55080 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        reading      mean       rms       sum    stddev  square_sum\n",
              "0      0.088505  0.000150  0.004467  0.000150  0.000000    0.000150\n",
              "1      0.088505  0.000300  0.006317  0.000300  0.000150    0.000300\n",
              "2      0.088505  0.000449  0.007737  0.000449  0.000300    0.000449\n",
              "3      0.088505  0.000599  0.008934  0.000599  0.000450    0.000599\n",
              "4      0.088505  0.000749  0.009988  0.000749  0.000600    0.000749\n",
              "5      0.088505  0.000899  0.010941  0.000899  0.000750    0.000899\n",
              "6      0.088505  0.001048  0.011818  0.001048  0.000899    0.001048\n",
              "7      0.089522  0.001200  0.012652  0.001200  0.001049    0.001200\n",
              "8      0.090539  0.001353  0.013452  0.001353  0.001201    0.001353\n",
              "9      0.091556  0.001508  0.014224  0.001508  0.001354    0.001508\n",
              "10     0.091556  0.001663  0.014955  0.001663  0.001509    0.001663\n",
              "11     0.091556  0.001818  0.015653  0.001818  0.001664    0.001818\n",
              "12     0.091556  0.001973  0.016321  0.001973  0.001820    0.001973\n",
              "13     0.091556  0.002128  0.016962  0.002128  0.001975    0.002128\n",
              "14     0.091556  0.002283  0.017580  0.002283  0.002130    0.002283\n",
              "15     0.091556  0.002438  0.018178  0.002438  0.002285    0.002438\n",
              "16     0.091556  0.002593  0.018756  0.002593  0.002440    0.002593\n",
              "17     0.091556  0.002748  0.019316  0.002748  0.002595    0.002748\n",
              "18     0.090539  0.002901  0.019850  0.002901  0.002750    0.002901\n",
              "19     0.091556  0.003056  0.020380  0.003056  0.002903    0.003056\n",
              "20     0.091556  0.003211  0.020898  0.003211  0.003058    0.003211\n",
              "21     0.092574  0.003367  0.021414  0.003367  0.003214    0.003367\n",
              "22     0.091556  0.003522  0.021906  0.003522  0.003370    0.003522\n",
              "23     0.092574  0.003679  0.022399  0.003679  0.003525    0.003679\n",
              "24     0.092574  0.003836  0.022881  0.003836  0.003682    0.003836\n",
              "25     0.093591  0.003994  0.023364  0.003994  0.003839    0.003994\n",
              "26     0.093591  0.004152  0.023836  0.004152  0.003998    0.004152\n",
              "27     0.094608  0.004313  0.024310  0.004313  0.004156    0.004313\n",
              "28     0.093591  0.004471  0.024765  0.004471  0.004316    0.004471\n",
              "29     0.094608  0.004631  0.025221  0.004631  0.004475    0.004631\n",
              "...         ...       ...       ...       ...       ...         ...\n",
              "55050  0.501786  0.867246  0.876401  0.867246  0.867162    0.867246\n",
              "55051  0.499672  0.868092  0.876764  0.868092  0.868011    0.868092\n",
              "55052  0.492853  0.868926  0.877117  0.868926  0.868858    0.868926\n",
              "55053  0.492708  0.869760  0.877469  0.869760  0.869693    0.869760\n",
              "55054  0.503123  0.870611  0.877836  0.870611  0.870527    0.870611\n",
              "55055  0.506899  0.871469  0.878209  0.871469  0.871379    0.871469\n",
              "55056  0.501572  0.872318  0.878574  0.872318  0.872238    0.872318\n",
              "55057  0.502074  0.873168  0.878939  0.873168  0.873087    0.873168\n",
              "55058  0.502790  0.874018  0.879305  0.874018  0.873938    0.874018\n",
              "55059  0.512102  0.874885  0.879685  0.874885  0.874790    0.874885\n",
              "55060  0.513111  0.875753  0.880066  0.875753  0.875657    0.875753\n",
              "55061  0.509301  0.876615  0.880442  0.876615  0.876526    0.876615\n",
              "55062  0.505269  0.877470  0.880811  0.877470  0.877389    0.877470\n",
              "55063  0.503785  0.878323  0.881178  0.878323  0.878244    0.878323\n",
              "55064  0.500663  0.879170  0.881540  0.879170  0.879098    0.879170\n",
              "55065  0.503140  0.880022  0.881906  0.880022  0.879946    0.880022\n",
              "55066  0.500364  0.880868  0.882267  0.880868  0.880798    0.880868\n",
              "55067  0.500318  0.881715  0.882628  0.881715  0.881645    0.881715\n",
              "55068  0.499835  0.882561  0.882989  0.882561  0.882493    0.882561\n",
              "55069  0.507083  0.883419  0.883360  0.883419  0.883340    0.883419\n",
              "55070  0.504203  0.884272  0.883726  0.884272  0.884198    0.884272\n",
              "55071  0.510440  0.885136  0.884101  0.885136  0.885052    0.885136\n",
              "55072  0.515055  0.886008  0.884484  0.886008  0.885917    0.886008\n",
              "55073  0.506062  0.886864  0.884852  0.886864  0.886789    0.886864\n",
              "55074  0.505512  0.887720  0.885220  0.887720  0.887647    0.887720\n",
              "55075  0.506169  0.888576  0.885588  0.888576  0.888503    0.888576\n",
              "55076  0.505644  0.889432  0.885956  0.889432  0.889360    0.889432\n",
              "55077  0.507965  0.890292  0.886327  0.890292  0.890217    0.890292\n",
              "55078  0.512410  0.891159  0.886704  0.891159  0.891077    0.891159\n",
              "55079  0.517087  0.892034  0.887088  0.892034  0.891945    0.892034\n",
              "\n",
              "[55080 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yfUtRYeAvxi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "4e8c1ce3-cbec-4a9b-c0e1-ca0165a8d1b1"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "layers.Dense(500, activation='relu',input_shape=(6,)), \n",
        "layers.Dense(500, activation='relu'),\n",
        "layers.Dense(500, activation='relu'),\n",
        "layers.Dense(500, activation='relu'),\n",
        "layers.Dense(500, activation='relu'),\n",
        "layers.Dense(500, activation='relu'),\n",
        "layers.Dense(6, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "input1=np.array(input1)\n",
        "model.fit(input1, emg_labels, epochs=100, batch_size=100)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "55080/55080 [==============================] - 3s 50us/sample - loss: 0.7876 - acc: 0.6758\n",
            "Epoch 2/100\n",
            "55080/55080 [==============================] - 2s 45us/sample - loss: 0.6571 - acc: 0.7320\n",
            "Epoch 3/100\n",
            "55080/55080 [==============================] - 2s 45us/sample - loss: 0.5830 - acc: 0.7633\n",
            "Epoch 4/100\n",
            "28900/55080 [==============>...............] - ETA: 1s - loss: 0.5704 - acc: 0.7681"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-f3c341e8bbb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0minput1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memg_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}